{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMQ/2msI9GcMh5I5ITsY09H"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# Install necessary packages and set up the environment\n","!apt-get update -qq\n","!apt-get install -y xvfb ffmpeg\n","!pip install gym[atari] stable-baselines3 gym[accept-rom-license] shimmy pyvirtualdisplay\n","!ale-import-roms\n","!pip install --upgrade stable-baselines3 gym\n","\n","import gym\n","from stable_baselines3 import DQN\n","from stable_baselines3.common.vec_env import VecFrameStack, SubprocVecEnv\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from pyvirtualdisplay import Display\n","\n","# Set up virtual display\n","display = Display(visible=0, size=(1400, 900))\n","display.start()\n","\n","# Create the environment\n","def make_env():\n","    env = gym.make('MsPacman-v4', render_mode='rgb_array')  # Use 'rgb_array' to capture frames\n","    print(\"Environment created\")\n","    return env\n","\n","# Create vectorized environments\n","num_envs = 1  # Number of parallel environments\n","env = SubprocVecEnv([make_env for _ in range(num_envs)])  # Vectorized environment\n","env = VecFrameStack(env, n_stack=4)  # Stack frames\n","print(\"Environment stacked and vectorized\")\n","\n","# Initialize the model\n","model = DQN('CnnPolicy', env, verbose=1)\n","print(\"Model initialized\")\n","\n","# Train the model with fewer timesteps\n","model.learn(total_timesteps=10)\n","print(\"Model trained\")\n","\n","# Define the number of episodes for evaluation\n","num_episodes = 1\n","\n","# Evaluate the model\n","def evaluate_model(model, env, num_episodes=1):\n","    all_rewards = []\n","    for _ in range(num_episodes):\n","        obs = env.reset()\n","        if isinstance(obs, tuple):\n","            obs = obs[0]\n","        done = False\n","        total_reward = 0\n","        while not done:\n","            action, _states = model.predict(obs)\n","            obs, reward, done, info = env.step(action)\n","            total_reward += reward\n","\n","            # Render the environment\n","            img = env.render(mode='rgb_array')  # Get the image\n","            if img is not None:\n","                if isinstance(img, list):  # Handle list of frames\n","                    img = img[0]\n","                img = np.array(img)  # Ensure img is a numpy array\n","                if img.shape[-1] == 12:  # Handle more than 3 channels\n","                    img = img[:, :, :3]  # Use only the first 3 channels (RGB)\n","                plt.imshow(img)\n","                plt.title(\"DQN Playing\")\n","                plt.axis('off')\n","                plt.show()\n","            else:\n","                print(\"Rendering returned None\")\n","\n","            if done:\n","                break\n","\n","        all_rewards.append(total_reward)\n","    return np.mean(all_rewards)\n","\n","# Run evaluation\n","avg_reward = evaluate_model(model, env, num_episodes)\n","print(f\"Average reward over {num_episodes} episodes: {avg_reward}\")\n","\n","# Close the environment\n","env.close()\n","print(\"Environment closed\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1VdPrib5wya_-2RNuVkdbjdCsz9CHAR1M"},"id":"PxpcNwRK5chf","outputId":"8304fced-9c91-4991-ccce-fac1cf1055f5"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}